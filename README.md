# History-of-Deep-Learning (inspire by @adam-maj)

Three stage of implemntation : From Scrath, In PyTorch And In Jax(not all but some).

## Totalcount : (1/31)

## 01-deep-neural-networks

| Concept       | Complete |
|---------------|-------|
| BackPropagation | ✅   |
| CNN           | ✅   |
| AlexNet       | ✅   |
| U-net         | ✅   |

## 02-optimization-and-regularization

| Concept         | Complete |
|-----------------|-------|
| weights-decay   |    |
| relu            |    |
| residuals       |    |
| dropout         |    |
| batch-norm      |    |
| layer-norm      |    |
| gelu            |    |
| adam            |    |

## 03-sequence-modeling

| Concept           | Complete |
|-------------------|-------|
| rnn               |    |
| lstm              |    |
| learning-to-forget|    |
| word2vec          |    |
| seq2seq           |    |
| attention         |    |
| mixture-of-experts|    |

## 04-transformer

| Concept            | Complete |
|--------------------|-------|
| transformer        |    |
| bert               |    |
| t5                 |    |
| gpt                |    |
| lora               |    |
| rlhf               |    |
| vision-transformer |    |

## 05-image-generation

| Concept         | Complete |
|-----------------|-------|
| gans            |    |
| vae             |    |
| diffusion       |    |
| clip            |    |
| dall-e          |    |

---
