{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN (work in progress)\n",
    "\n",
    "\n",
    "> **why we cannot used ANN or CNN for sequential data ?**\n",
    "\n",
    "- the text data is not of same size.(each example can have the different lenght).\n",
    "\n",
    "- and cnn or ann canot deal with the input of diff-diff lenght.\n",
    "\n",
    "- what if convert the every smaple into same size but the amount of unsessary data that we gonna create is crazy not computer efficient at all.\n",
    "\n",
    "- and also at the time of inferece if we input have diff length then the zero padding is also not gonna work.(i.e larger than out highest our training sample lenght)\n",
    "\n",
    "- and one thing in ANN or CNN we pass the data at a same time this can cuase the big probelm. \n",
    "\n",
    "- cuase the meaining of sentence cann be change or look liek randome noise caues in text the most imp thing is the squence of the words.\n",
    "\n",
    "- by design the ann cannot remember anything due it we lose the semantic meaning.\n",
    "\n",
    "> **How RNN solve this problem ?** \n",
    "\n",
    "- rnn can handle the sequential data.(mostly text data).\n",
    "\n",
    "- rnn has this feature due to it can remember the previous features.\n",
    "\n",
    "> **RNN-Architecure**\n",
    "\n",
    "- there are three main arc -> 1. many to one , 2. One to many , 3. many to many.\n",
    "\n",
    "- lets start our discussion with many to one.\n",
    "\n",
    "- how rnn solve the ann probelm is withe system like self-feedback loop and time-stamp.\n",
    "\n",
    "- before passing our data into rnn we need to convert data into tokens(brekaing sentence into small chunks) then need to pass.(sequentail information saved). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting jax\n",
      "  Downloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22 in /Users/saurabh/Library/Python/3.9/lib/python/site-packages (from jax) (1.26.4)\n",
      "Collecting ml-dtypes>=0.2.0\n",
      "  Downloading ml_dtypes-0.4.0-cp39-cp39-macosx_10_9_universal2.whl (390 kB)\n",
      "\u001b[K     |████████████████████████████████| 390 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.9 in /Users/saurabh/Library/Python/3.9/lib/python/site-packages (from jax) (1.13.0)\n",
      "Collecting jaxlib<=0.4.30,>=0.4.27\n",
      "  Downloading jaxlib-0.4.30-cp39-cp39-macosx_11_0_arm64.whl (66.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 66.7 MB 81 kB/s  eta 0:00:01     |███████████████▉                | 33.1 MB 1.2 MB/s eta 0:00:29     |███████████████████████████▋    | 57.6 MB 762 kB/s eta 0:00:12\n",
      "\u001b[?25hCollecting opt-einsum\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 342 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.6 in /Users/saurabh/Library/Python/3.9/lib/python/site-packages (from jax) (7.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/saurabh/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.6->jax) (3.18.1)\n",
      "Installing collected packages: ml-dtypes, opt-einsum, jaxlib, jax\n",
      "Successfully installed jax-0.4.30 jaxlib-0.4.30 ml-dtypes-0.4.0 opt-einsum-3.3.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        1.05      2.1       3.1499999 4.2      ]\n"
     ]
    }
   ],
   "source": [
    "def selu(x, alpha=1.67, lmbda=1.05):\n",
    "  return lmbda * jnp.where(x > 0, x, alpha * jnp.exp(x) - alpha)\n",
    "\n",
    "x = jnp.arange(5.0)\n",
    "print(selu(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.29 ms ± 728 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "from jax import random\n",
    "\n",
    "key = random.key(1701)\n",
    "x = random.normal(key, (1_000_000,))\n",
    "%timeit selu(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425 µs ± 6.92 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "from jax import jit\n",
    "\n",
    "selu_jit = jit(selu)\n",
    "_ = selu_jit(x)  # compiles on first call\n",
    "%timeit selu_jit(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, rnn_layer, **kwargs):\n",
    "        super(RNNModel, self).__init__(**kwargs)\n",
    "        self.rnn = rnn_layer\n",
    "        if self.rnn.bidirectional:\n",
    "            self.num_directions = 2\n",
    "        else:\n",
    "            self.num_directions = 1\n",
    "        self.linear = nn.Linear(\n",
    "            self.num_directions * self.rnn.hidden_size, self.rnn.input_size)\n",
    "\n",
    "    # forward\n",
    "\n",
    "    def forward(self, inputs, state):\n",
    "        X = F.one_hot(inputs.T.long(), self.rnn.input_size)\n",
    "        X = X.to(torch.float32)\n",
    "        Y, state = self.rnn(X, state)\n",
    "        output = self.linear(Y.reshape((-1, Y.shape[-1])))\n",
    "        return output, begin_state\n",
    "\n",
    "\n",
    "    #begin state\n",
    "\n",
    "    def begin_state(self, device, batch_size=1):\n",
    "        tensor = torch.zeros((self.num_directions * self.rnn.num_layers, \n",
    "                              batch_size, self.rnn.hidden_size), \n",
    "                             device=device)\n",
    "        if isinstance(self.rnn, nn.LSTM):\n",
    "            return (tensor, tensor) \n",
    "        else:\n",
    "            return tensor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
