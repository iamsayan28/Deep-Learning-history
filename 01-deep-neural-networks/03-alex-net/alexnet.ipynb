{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before AlexNet: The Pre-Deep Neural Network ERA\n",
    "\n",
    "---\n",
    "\n",
    "- Researchers used to trained machine learning models on CPUs.\n",
    "\n",
    "- CPUs had limited capacity so were not able to train the large models.\n",
    "- Training with large datasets was challenging.\n",
    "- LeNet was one of the first models trained on medium-sized datasets, but not truly large ones.\n",
    "- Hardware limitations were a major factor in using small datasets with fewer parameters:\n",
    "  - NVIDIA's GeForce 256 from 1999 could process at most 480 million floating-point operations.\n",
    "  \n",
    "  - There were no meaningful programming frameworks like CUDA to operate these accelerators.\n",
    "  - In contrast, today's accelerators can perform over 1000 TFLOPs per device.\n",
    "- Activation functions were not as effective.\n",
    "- Moreover, datasets were still relatively small: OCR on 60,000 low-resolution 28 X 28 pixel images was considered a highly challenging task.\n",
    "---\n",
    "## ImageNet \n",
    "\n",
    "-  ImageNet was released in 2009, the dataset comprised 12 million images across 22,000 categories.\n",
    "\n",
    "-------\n",
    "\n",
    "![imagnet](../../images/imagent.webp)\n",
    "\n",
    "-------\n",
    "\n",
    "\n",
    "- The team which created the ImageNet Datasets started organising the ImageNet Large Scale Visual Recognition Challenge (ILSVRC).\n",
    "\n",
    "- The team with lowest error rate will win.\n",
    "- The ImageNet Challenge becomes popular among the reasechers and become the standard to evaluate the performance of the vision models.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet: The Beginning of the Deep Neural Network ERA\n",
    "\n",
    "---\n",
    "\n",
    "- AlexNet had 60 million parameters.\n",
    "\n",
    "- Training on CPUs was impractical due to the large number of parameters.\n",
    "- A major breakthrough occurred when Alex Krizhevsky and Ilya Sutskever implemented a deep CNN that could run on GPUs.\n",
    "- They realized that the computational bottlenecks in CNNs, such as convolutions and matrix multiplications, could be parallelized in hardware.\n",
    "- Using two NVIDIA GTX 580s with 3GB of memory, each capable of 1.5 TFLOPs, they implemented fast convolutions. Training one model on a single GPU was not possible at the time.\n",
    "- The two halves of the network would communicate at specific layers to ensure they were not training two separate models.\n",
    "- AlexNet was released in 2012 and won the ImageNet competition by a large margin in error rate.\n",
    "- The authors introduced numerous methods to improve the performance of AlexNet.\n",
    "- This paper completely changed the AI field.\n",
    "\n",
    "---\n",
    "- ![imgnet](../../images/imagnet-win.webp) \n",
    "----\n",
    "## Architecture\n",
    "\n",
    "**The network consists of 8 learned layers:**\n",
    "- 5 convolutional layers\n",
    "- 3 fully-connected layers\n",
    "---\n",
    "![arc](../../images/alexnet-arc.webp)\n",
    "\n",
    "---\n",
    "### ReLU Nonlinearity\n",
    "\n",
    "- Used f(x) = max(0, x) as the activation function.\n",
    "\n",
    "- Trains several times faster than tanh units.\n",
    "- Does not require input normalization to prevent saturation.\n",
    "---\n",
    "- ![relu](../../images/relu.webp)\n",
    "\n",
    "\n",
    "### Local Response Normalization\n",
    "\n",
    "- Applied after the ReLU activation in certain layers (specifically after the first and second convolutional layers in AlexNet).\n",
    "\n",
    "- By normalizing the responses, it prevents a single feature from dominating.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Overlapping Pooling\n",
    "\n",
    "- Pooling layers summarize outputs of neighboring groups of neurons\n",
    "\n",
    "- Use overlapping pooling: z > s, where z is the filter size and s is the stride\n",
    "- Reduces top-1 and top-5 error rates rates by 0.4% and 0.3%. \n",
    "---\n",
    "- ![overlapping](../../images/overlapping.webp)\n",
    "\n",
    "---\n",
    "\n",
    "## Reducing Overfitting\n",
    "\n",
    "### Data Augmentation\n",
    "\n",
    "Two forms of data augmentation were used:\n",
    "\n",
    "1. Image translations and horizontal reflections\n",
    "   - Extract random 224x224 patches (and their horizontal reflections) from 256x256 images\n",
    "   - Increases training set by a factor of 2048\n",
    "\n",
    "2. Altering RGB channel intensities\n",
    "   - Performs PCA on RGB pixel values in training set\n",
    "   - Adds multiples of principal components to each training image\n",
    "\n",
    "### Dropout\n",
    "\n",
    "- Randomly drops out neurons during training (probability 0.5)\n",
    "\n",
    "- Reduces complex co-adaptations of neurons\n",
    "- Forces the network to learn more robust features\n",
    "- Used in the first two fully-connected layers\n",
    "---\n",
    "- ![dorpout](../../images/dropout2.svg)\n",
    "\n",
    "--- \n",
    "\n",
    "## GPU Utilization \n",
    "\n",
    "- The network was trained using two NVIDIA GTX 580 GPUs\n",
    "\n",
    "- Each GPU responsible for roughly half of the neurons/kernels\n",
    "- One GPU handles top half of kernels/neurons and  Other GPU handles bottom half, Reduces training time significantly.\n",
    "\n",
    "## Training \n",
    "\n",
    "- Stochastic gradient descent with batch size of 128\n",
    "\n",
    "- Momentum of 0.9 and weight decay of 0.0005\n",
    "- Learning rate initialized at 0.01, reduced by factor of 10 when validation error rate stopped improving\n",
    "- Trained for approximately 90 epochs through the training set of 1.2 million images and 1000 classes\n",
    "\n",
    "---\n",
    "\n",
    "## Read more, Learn More and Build more\n",
    "\n",
    "#### Reding List :\n",
    "\n",
    "1. ImageNet Classification with Deep Convolutional Neural Networks [Link](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)\n",
    "\n",
    "2. AlexNet and ImageNet: The Birth of Deep Learning [Link](https://www.pinecone.io/learn/series/image-search/imagenet/)\n",
    "\n",
    "3. D2L book [Link](https://d2l.ai/chapter_convolutional-modern/alexnet.html)\n",
    "\n",
    "#### Videos :\n",
    "\n",
    "1. AlexNet and ImageNet: The Birth of Deep Learning [Link](https://youtu.be/c_u4AHNjOpk?si=htGGLTCF2_ZC3ajO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alexnet In Work (Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface\n",
      "  Downloading huggingface-0.0.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Downloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\n",
      "Installing collected packages: huggingface\n",
      "Successfully installed huggingface-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/saurabh/projects/env/lib/python3.12/site-packages (4.66.2)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip3 install tqdm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "!pip3 install tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# import dataset from HuggingFace\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m      5\u001b[0m imagenet \u001b[38;5;241m=\u001b[39m load_dataset(\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaysee/tiny-imagenet\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m     ignore_verifications\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m     file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;66;03m# set to True if seeing splits Error\u001b[39;00m\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m~/projects/env/lib/python3.12/site-packages/datasets/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ruff: noqa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.18.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowBasedBuilder, BeamBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
      "File \u001b[0;32m~/projects/env/lib/python3.12/site-packages/datasets/arrow_dataset.py:62\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpa\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpc\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CommitInfo, CommitOperationAdd, CommitOperationDelete, DatasetCard, DatasetCardData, HfApi\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pool\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m thread_map\n",
      "File \u001b[0;32m~/projects/env/lib/python3.12/site-packages/huggingface_hub/__init__.py:487\u001b[0m, in \u001b[0;36m_attach.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m attr_to_modules:\n\u001b[1;32m    486\u001b[0m     submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 487\u001b[0m     submod \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(submod_path)\n\u001b[1;32m    488\u001b[0m     attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(submod, name)\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;66;03m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;66;03m# the module is accessible on the package.\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/env/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m~/projects/env/lib/python3.12/site-packages/huggingface_hub/hf_api.py:47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPError\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;28;01mas\u001b[39;00m base_tqdm\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m thread_map\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_commit_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     51\u001b[0m     CommitOperation,\n\u001b[1;32m     52\u001b[0m     CommitOperationAdd,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m     _warn_on_overwriting_operations,\n\u001b[1;32m     60\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "# import dataset from HuggingFace\n",
    "import sys\n",
    "from datasets import load_dataset\n",
    "\n",
    "imagenet = load_dataset(\n",
    "    'Maysee/tiny-imagenet',\n",
    "    split='valid',\n",
    "    ignore_verifications=True,\n",
    "    file=sys.stdout# set to True if seeing splits Error\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
