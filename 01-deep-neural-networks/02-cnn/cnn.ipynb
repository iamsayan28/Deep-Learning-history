{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building The CNN And Learning Almost Everything About It."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Why CNN and Not MLP For Images ?\n",
    "#### 2. How CNN works ? - > Layers : Convolutional, Pooling and Fully Connected Layers \n",
    "#### 3. How Backprop Happens In CNN ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](../../images/cnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Why We Use The CNN And Not MLP For Images ?\n",
    "\n",
    "CNN Handles the Image datasets better than the MLP \n",
    "and there are two main reason to it : ***1. Sparse Connectivety and 2. Parameter Shairng***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sparse Connectivity :` Sparse connectivity point towards that each neuron in a convolutional layer of a CNN is only connected to a small, localized region of the input image, rather than being fully connected to the entire input. This localized region is known as the receptive field.\n",
    "\n",
    "Local Receptive Fields: In CNNs, each convolutional kernels operates over a small patch of the input image. This means that neurons in the convolutional layer only focus on small regions of the input, making the network more efficient by reducing the number of parameters and computations.\n",
    "\n",
    "`Parameter Sharing:` The same convolutional filter is applied to entire input image. This parameter sharing allows CNNs to capture features like edges, textures, and patterns regardless of their position in the image.\n",
    "\n",
    "#### Why not MLP ?\n",
    "\n",
    "`High Number of Parameters:` For an image of size 32x32 with 3 color channels, a single neuron in the first hidden layer of an MLP would have ***32 × 32 × 3 = 3072*** connections. With a large number of neurons, this quickly becomes impractical.\n",
    "\n",
    "`Lack of Locality:` MLPs treat all input pixels equally without considering the spatial structure of the image. This lack of locality makes it harder for MLPs to capture local patterns and structures that are important for image recognition tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d Implementation:\n",
      " [[11. 25. 32. 13.]\n",
      " [19. 25. 24. 13.]\n",
      " [13. 28. 25. 17.]\n",
      " [11. 17. 14.  9.]]\n",
      "SciPy Results:\n",
      " [[11 25 32 13]\n",
      " [19 25 24 13]\n",
      " [13 28 25 17]\n",
      " [11 17 14  9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "def conv2d(X, W, p=(0, 0), s=(1, 1)):\n",
    "    W_rot = np.array(W)[::-1, ::-1]  # Rotate the filter\n",
    "    X_orig = np.array(X)\n",
    "    \n",
    "    # Pad the input array\n",
    "    n1 = X_orig.shape[0] + 2*p[0]\n",
    "    n2 = X_orig.shape[1] + 2*p[1]\n",
    "    X_padded = np.zeros(shape=(n1, n2))\n",
    "    X_padded[p[0]:p[0] + X_orig.shape[0], p[1]:p[1] + X_orig.shape[1]] = X_orig\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    # Iterate over the output array dimensions\n",
    "    for i in range(0, int((X_padded.shape[0] - W_rot.shape[0]) / s[0]) + 1, s[0]):\n",
    "        row = []\n",
    "        for j in range(0, int((X_padded.shape[1] - W_rot.shape[1]) / s[1]) + 1, s[1]):\n",
    "            X_sub = X_padded[i:i + W_rot.shape[0], j:j + W_rot.shape[1]]\n",
    "            conv_result = np.sum(X_sub * W_rot)\n",
    "            row.append(conv_result)\n",
    "        res.append(row)\n",
    "    \n",
    "    return np.array(res)\n",
    "\n",
    "X = [[1, 3, 2, 4], [5, 6, 1, 3], [1, 2, 0, 2], [3, 4, 3, 2]]\n",
    "W = [[1, 0, 3], [1, 2, 1], [0, 1, 1]]\n",
    "print('Conv2d Implementation:\\n',\n",
    "conv2d(X, W, p=(1, 1), s=(1, 1))) \n",
    "print('SciPy Results:\\n',scipy.signal.convolve2d(X, W, mode='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
