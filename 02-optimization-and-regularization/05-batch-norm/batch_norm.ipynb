{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets understand the batch-norm \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> **Internal Covariate Shift:**\n",
    "\n",
    "- Internal covariate shift refers to the change in the distribution of network activations due to the updating of network parameters during training.\n",
    "\n",
    "- Batch normalization helps to reduce this internal covariate shift by normalizing the output of each layer to have a mean of zero and a variance of one.\n",
    "\n",
    "- By normalizing the inputs of each layer, batch normalization ensures that the distribution of the activations remains consistent during training, which helps in stabilizing and speeding up the training process.\n",
    "\n",
    "- example : - if we train the model of image classification of rose or not rose but with only images of red roses and at time of testing we provide the images of roses with diff colour then model might not recosined it. (high level example)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
