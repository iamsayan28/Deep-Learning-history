{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Does the World Need Regularization?\n",
    "\n",
    "Deep learning models generally tend to overfit, especially when the model is too complex. This means that while the model performs perfectly on the training dataset, it doesn't perform as well on the test dataset. To reduce overfitting, we can take measures both on the model and the dataset.\n",
    "\n",
    "Increasing the size of the dataset can help, but it's often costly, time-consuming, and sometimes not possible. Assuming we have a high-quality dataset, we can optimize the model using techniques like early stopping, dropout, and L2 regularization.\n",
    "\n",
    "---\n",
    "\n",
    "### L2 Regularization\n",
    "\n",
    "L2 regularization, also known as Ridge regularization, works by adding a penalty term to the loss function, which helps reduce the weights of the model during updates. This is also known as weight decay. \n",
    "\n",
    "***The penalty term for L2 regularization is given by the formula:***\n",
    "\n",
    "$$ L_{reg} = L + \\frac{\\lambda}{2} \\sum_{i=1}^n w_i^2 $$\n",
    "\n",
    "where \\( L \\) is the original loss function (e.g., mean squared error for regression), \\( \\lambda \\) is the regularization parameter, and \\( w_i \\) represents the model weights. This formula helps keep the weight values close to zero but not exactly zero, preventing the model from becoming too complex.\n",
    "\n",
    "---\n",
    "\n",
    "#### Internal Workings\n",
    "\n",
    "1. **Gradient Descent Adjustment**:\n",
    "   - During training, gradient descent updates the weights to minimize the loss function.\n",
    "   - With L2 regularization, the weight update rule becomes:\n",
    "     $$ w_i = w_i - \\eta \\left( \\frac{\\partial L}{\\partial w_i} + \\lambda w_i \\right) $$\n",
    "   - Here, \\( \\eta \\) is the learning rate.\n",
    "   - The term \\( \\lambda w_i \\) effectively shrinks the weights during each update, preventing them from growing too large.\n",
    "   -  The squared term in the L2 regularization formula is to improve computational efficiency by avoiding the need    for square root calculations during backpropagation. This simplifies the derivative computation, making the training process faster and more efficient.\n",
    "\n",
    "2. **Impact on Weight Magnitudes**:\n",
    "   - The addition of \\( \\lambda w_i \\) term ensures that the weights are not only driven by the gradient of the loss but also by their own magnitude.\n",
    "   - This keeps the weights small and avoids overfitting by penalizing large weights more heavily.\n",
    "---\n",
    "#### Usefulness in bfloat16 for LLMs and CLIP etc\n",
    "\n",
    "In large language models (LLMs) and CLIP model training, the use of bfloat16 (Brain Floating Point) is common due to its benefits in reducing memory usage and increasing computational efficiency. bfloat16 has a wider dynamic range compared to FP16, which makes it suitable for training large models.\n",
    "\n",
    "1. **Numerical Stability**:\n",
    "   - L2 regularization contributes to numerical stability during training by keeping the weights small. This is especially important in bfloat16, where the precision is lower than FP32.\n",
    "   - Smaller weights reduce the risk of overflow or underflow during arithmetic operations, which can be a concern in lower precision formats like bfloat16.\n",
    "\n",
    "2. **Gradient Scaling**:\n",
    "   - In mixed precision training (using both FP32 and bfloat16), gradients can be scaled to maintain precision. L2 regularization helps ensure that the gradients do not become excessively large, which could otherwise lead to instability.\n",
    "   - By keeping the weights and their updates within a manageable range, L2 regularization aids in maintaining the effectiveness of gradient scaling techniques.\n",
    "\n",
    "---\n",
    "#### In Short :\n",
    "\n",
    "- Regularization is a common method for dealing with overfitting. It adds a penalty term to the loss function on the training set to reduce the complexity of the learned model.\n",
    "\n",
    "- One particular choice for keeping the model simple is weight decay using an  penalty. This leads to weight decay in the update steps of the learning algorithm.\n",
    "\n",
    "- The weight decay functionality is provided in optimizers from deep learning frameworks.\n",
    "\n",
    "- Different sets of parameters can have different update behaviors within the same training loop.\n",
    "\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
